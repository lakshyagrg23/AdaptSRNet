{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AdaptSRNet\n",
        "\n",
        "This notebook trains the **enhanced AdaptSRNet** model (1-2M parameters) for steganalysis on the WOW algorithm (0.4bpp payload) using **PyTorch Lightning**."
      ],
      "metadata": {
        "id": "r2IY1Qo-Xa_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfNV9_axXT5s"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== CONFIG CELL =====================\n",
        "import torch\n",
        "\n",
        "#  Paths (manual setup)\n",
        "COVER_DIR = \"/kaggle/input/bossbase-bows2/GBRASNET/BOSSbase-1.01/cover\"\n",
        "STEGO_DIR = \"/kaggle/input/bossbase-bows2/GBRASNET/BOSSbase-1.01/stego/WOW/0.4bpp/stego\"\n",
        "\n",
        "#  Training parameters\n",
        "BATCH_SIZE = 4       # Increase if you have more GPU memory (e.g., 8 or 16)\n",
        "IMG_SIZE = 256\n",
        "EPOCHS = 50          # Can increase to 100 for better convergence\n",
        "NUM_WORKERS = 4\n",
        "SEED = 42\n",
        "LR = 1e-4           # Will be adjusted by CosineAnnealingWarmRestarts\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Using device(s): {torch.cuda.device_count()} GPU(s)\")\n",
        "print(f\"Device type: {DEVICE}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Cover directory: {COVER_DIR}\")\n",
        "print(f\"Stego directory: {STEGO_DIR}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"Max epochs: {EPOCHS}\")\n",
        "print(f\"Learning rate: {LR}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Set memory fragmentation handling\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "torch.cuda.empty_cache()\n",
        "# ========================================================\n"
      ],
      "metadata": {
        "id": "9vLLo7Q8XfzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools --quiet\n",
        "!pip install pytorch-lightning --quiet\n",
        "!pip install tokenizers==0.13.3 --quiet\n",
        "!pip install transformers==4.28.1 --quiet"
      ],
      "metadata": {
        "id": "aBrHs5i9Xh5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from torchmetrics.classification import Accuracy, F1Score\n",
        "\n",
        "pl.seed_everything(SEED)"
      ],
      "metadata": {
        "id": "g5Ht4zHHXj19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import os, re\n",
        "\n",
        "def normalize_name(name):\n",
        "    \"\"\"\n",
        "    Normalize filenames by:\n",
        "    - removing prefixes (WOW_, HILL_, etc.)\n",
        "    - removing payload suffix (_0.2bpp, _02bpp)\n",
        "    - stripping zeros from numbers (00001 -> 1)\n",
        "    \"\"\"\n",
        "    name = Path(name).stem\n",
        "    # Remove common stego prefixes or suffixes\n",
        "    name = re.sub(r'^(WOW_|HILL_|HUGO_|MiPOD_|S-UNIWARD_)', '', name, flags=re.IGNORECASE)\n",
        "    name = re.sub(r'(_0?\\\\.\\\\d+bpp|_\\\\d+bpp)$', '', name, flags=re.IGNORECASE)\n",
        "    # Remove leading zeros in numeric part\n",
        "    name = re.sub(r'^0+', '', name)\n",
        "    return name\n",
        "\n",
        "def collect_pairs(cover_dir, stego_dir):\n",
        "    cover_paths = sorted([p for p in glob(os.path.join(cover_dir, '*')) if p.lower().endswith(('.pgm', '.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "    stego_paths = sorted([p for p in glob(os.path.join(stego_dir, '*')) if p.lower().endswith(('.pgm', '.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "\n",
        "    cover_map = {normalize_name(p): p for p in cover_paths}\n",
        "    stego_map = {normalize_name(p): p for p in stego_paths}\n",
        "\n",
        "    common = sorted(set(cover_map.keys()) & set(stego_map.keys()))\n",
        "    pairs = [(cover_map[k], stego_map[k], k) for k in common]\n",
        "\n",
        "    print(f\"Found {len(pairs)} matching cover/stego pairs\")\n",
        "    if len(pairs) == 0:\n",
        "        print(\"No matches found â€” check filename formats or folder paths.\")\n",
        "    return pairs\n",
        "\n",
        "\n",
        "\n",
        "def make_splits_from_pairs(pairs, val_frac=0.1, test_frac=0.2, seed=42):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    rng.shuffle(pairs)\n",
        "    n = len(pairs)\n",
        "    ntest, nval = int(n * test_frac), int(n * val_frac)\n",
        "    test = pairs[:ntest]\n",
        "    val = pairs[ntest:ntest + nval]\n",
        "    train = pairs[ntest + nval:]\n",
        "    return {'train': train, 'val': val, 'test': test}\n",
        "\n",
        "\n",
        "pairs = collect_pairs(COVER_DIR, STEGO_DIR)\n",
        "splits = make_splits_from_pairs(pairs)\n",
        "print(\"Splits:\", {k: len(v) for k, v in splits.items()})\n"
      ],
      "metadata": {
        "id": "pos7dmzVXl1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PairedStegoDataset(Dataset):\n",
        "    def __init__(self, pairs, transform=None):\n",
        "        self.samples = []\n",
        "        for c, s, b in pairs:\n",
        "            self.samples.append((c, 0, b))\n",
        "            self.samples.append((s, 1, b))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label, base = self.samples[idx]\n",
        "        img = Image.open(path).convert('L')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label, base\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_loader = DataLoader(PairedStegoDataset(splits['train'], transform=train_tf), batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(PairedStegoDataset(splits['val'], transform=val_tf), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "print(\"DataLoaders ready\")"
      ],
      "metadata": {
        "id": "UBI8boNOXnzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------- Enhanced Learnable SRM layer with more filters ----------\n",
        "class LearnableSRMLayer(nn.Module):\n",
        "    def __init__(self, num_filters=64):  # Increased to 64 for better feature extraction\n",
        "        super().__init__()\n",
        "        self.num_filters = num_filters\n",
        "        srm_filters = self._initialize_srm_filters()\n",
        "        self.filters = nn.Parameter(srm_filters, requires_grad=True)\n",
        "        self.scale = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
        "\n",
        "    def _initialize_srm_filters(self):\n",
        "        # KV filter - effective for steganalysis\n",
        "        kv_filter = torch.tensor([\n",
        "            [-1,  2,  -2,  2, -1],\n",
        "            [ 2, -6,   8, -6,  2],\n",
        "            [-2,  8, -12,  8, -2],\n",
        "            [ 2, -6,   8, -6,  2],\n",
        "            [-1,  2,  -2,  2, -1]\n",
        "        ], dtype=torch.float32) / 12.0\n",
        "\n",
        "        # Edge detection filters\n",
        "        edge_h = torch.tensor([[-1, -1, -1], [0, 0, 0], [1, 1, 1]], dtype=torch.float32)\n",
        "        edge_v = torch.tensor([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=torch.float32)\n",
        "        laplacian = torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=torch.float32)\n",
        "\n",
        "        filters = []\n",
        "        for i in range(self.num_filters):\n",
        "            if i == 0:\n",
        "                f = kv_filter.clone()\n",
        "            elif i < 4:\n",
        "                f = torch.rot90(kv_filter, k=(i % 4), dims=[0,1])\n",
        "            elif i < 8:\n",
        "                # Add edge detection variations\n",
        "                base = edge_h if i % 2 == 0 else edge_v\n",
        "                f = F.pad(base, (1, 1, 1, 1), mode='constant', value=0)\n",
        "                f = torch.rot90(f, k=(i % 4), dims=[0,1])\n",
        "            elif i < 12:\n",
        "                # Laplacian variations\n",
        "                f = F.pad(laplacian, (1, 1, 1, 1), mode='constant', value=0)\n",
        "                f = torch.rot90(f, k=(i % 4), dims=[0,1])\n",
        "            else:\n",
        "                # Random variations of KV filter\n",
        "                f = kv_filter + torch.randn_like(kv_filter) * 0.02\n",
        "\n",
        "            f = f - f.mean()\n",
        "            f_norm = torch.norm(f)\n",
        "            if f_norm > 0:\n",
        "                f = f / f_norm\n",
        "            filters.append(f)\n",
        "\n",
        "        return torch.stack(filters, dim=0).unsqueeze(1)  # [num_filters,1,5,5]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x expected shape: [B, 1, H, W]\n",
        "        residuals = F.conv2d(x, self.filters, padding=2)  # -> [B, num_filters, H, W]\n",
        "        residuals = torch.tanh(residuals * self.scale)\n",
        "        return residuals\n",
        "\n",
        "\n",
        "# ---------- Squeeze-and-Excitation with better reduction ----------\n",
        "class SqueezeExcitation(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=16):\n",
        "        super().__init__()\n",
        "        reduced = max(1, in_channels // reduction_ratio)\n",
        "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
        "        self.excitation = nn.Sequential(\n",
        "            nn.Linear(in_channels, reduced, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(reduced, in_channels, bias=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.shape\n",
        "        s = self.squeeze(x).view(b, c)\n",
        "        e = self.excitation(s).view(b, c, 1, 1)\n",
        "        return x * e\n",
        "\n",
        "\n",
        "# ---------- Standard Conv Block (for richer features) ----------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel, stride=stride, padding=padding, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_ch)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "\n",
        "# ---------- Enhanced Residual Block with standard convolutions ----------\n",
        "class EnhancedResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, use_se=True):\n",
        "        super().__init__()\n",
        "        # Use standard convolutions for better feature extraction\n",
        "        self.conv1 = ConvBlock(in_channels, out_channels, stride=stride)\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "        self.se = SqueezeExcitation(out_channels, reduction_ratio=16) if use_se else nn.Identity()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.skip = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.skip = nn.Identity()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.skip(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.se(out)\n",
        "        out = out + identity\n",
        "        return self.relu(out)\n",
        "\n",
        "\n",
        "# ---------- Enhanced Multi-scale feature extractor ----------\n",
        "class MultiScaleFeatureExtractor(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        # out_channels should be divisible by 4\n",
        "        assert out_channels % 4 == 0\n",
        "        quarter = out_channels // 4\n",
        "\n",
        "        self.branch_1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, quarter, 1, bias=False),\n",
        "            nn.BatchNorm2d(quarter), nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.branch_3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, quarter, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(quarter), nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.branch_5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, quarter, 5, padding=2, bias=False),\n",
        "            nn.BatchNorm2d(quarter), nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.branch_pool = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, quarter, 1, bias=False),\n",
        "            nn.BatchNorm2d(quarter), nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.se = SqueezeExcitation(out_channels, reduction_ratio=16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b1 = self.branch_1x1(x)\n",
        "        b2 = self.branch_3x3(x)\n",
        "        b3 = self.branch_5x5(x)\n",
        "        b4 = self.branch_pool(x)\n",
        "        concat = torch.cat([b1, b2, b3, b4], dim=1)\n",
        "        return self.se(concat)\n",
        "\n",
        "\n",
        "# ---------- Spatial Attention Module (NEW - addresses shortcoming) ----------\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Channel-wise max and mean pooling\n",
        "        max_pool = torch.max(x, dim=1, keepdim=True)[0]\n",
        "        mean_pool = torch.mean(x, dim=1, keepdim=True)\n",
        "        combined = torch.cat([max_pool, mean_pool], dim=1)\n",
        "        attention = self.sigmoid(self.conv(combined))\n",
        "        return x * attention\n",
        "\n",
        "\n",
        "# ---------- CBAM (Convolutional Block Attention Module) ----------\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=16):\n",
        "        super().__init__()\n",
        "        self.channel_attention = SqueezeExcitation(in_channels, reduction_ratio)\n",
        "        self.spatial_attention = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.channel_attention(x)\n",
        "        x = self.spatial_attention(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------- Enhanced AdaptSRNet (target 1-2M params) ----------\n",
        "class AdaptSRNetEnhanced(nn.Module):\n",
        "    def __init__(self, num_classes=1, srm_filters=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1) Enhanced SRM preprocessing - outputs 64 channels\n",
        "        self.srm_layer = LearnableSRMLayer(num_filters=srm_filters)\n",
        "\n",
        "        # Enhanced channel plan for 1-2M parameters\n",
        "        init_ch = 64      # Increased from 32\n",
        "        ms_ch = 128       # Increased from 64\n",
        "        l1_ch = 128       # Increased from 64\n",
        "        l2_ch = 192       # Increased from 96\n",
        "        l3_ch = 256       # Increased from 128\n",
        "        l4_ch = 384       # Increased from 256\n",
        "\n",
        "        # 2) Initial conv with better capacity\n",
        "        self.init_conv = nn.Sequential(\n",
        "            nn.Conv2d(srm_filters, init_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(init_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(init_ch, init_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(init_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 3) Multi-scale feature extraction\n",
        "        self.multiscale = MultiScaleFeatureExtractor(init_ch, ms_ch)\n",
        "\n",
        "        # 4) Enhanced Residual layers with more blocks\n",
        "        self.layer1 = self._make_layer(ms_ch, l1_ch, num_blocks=3, stride=1)\n",
        "        self.layer2 = self._make_layer(l1_ch, l2_ch, num_blocks=3, stride=2)\n",
        "        self.layer3 = self._make_layer(l2_ch, l3_ch, num_blocks=4, stride=2)\n",
        "        self.layer4 = self._make_layer(l3_ch, l4_ch, num_blocks=3, stride=2)\n",
        "\n",
        "        # 5) Additional CBAM attention after layer4\n",
        "        self.cbam = CBAM(l4_ch, reduction_ratio=16)\n",
        "\n",
        "        # 6) Enhanced classifier head\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.global_max_pool = nn.AdaptiveMaxPool2d((1, 1))  # Add max pooling\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(l4_ch * 2, 256),  # Combined avg + max pooling features\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # Safe initialization\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, in_c, out_c, num_blocks, stride):\n",
        "        layers = [EnhancedResidualBlock(in_c, out_c, stride=stride, use_se=True)]\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(EnhancedResidualBlock(out_c, out_c, stride=1, use_se=True))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if getattr(m, \"weight\", None) is not None:\n",
        "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "                if getattr(m, \"bias\", None) is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "                if getattr(m, \"weight\", None) is not None:\n",
        "                    nn.init.ones_(m.weight)\n",
        "                if getattr(m, \"bias\", None) is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                if getattr(m, \"weight\", None) is not None:\n",
        "                    nn.init.normal_(m.weight, 0, 0.01)\n",
        "                if getattr(m, \"bias\", None) is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,1,H,W]\n",
        "        x = self.srm_layer(x)           # -> [B, 64, H, W]\n",
        "        x = self.init_conv(x)           # -> [B, 64, H, W]\n",
        "        x = self.multiscale(x)          # -> [B, 128, H, W]\n",
        "        x = self.layer1(x)              # -> [B, 128, H, W]\n",
        "        x = self.layer2(x)              # -> [B, 192, H/2, W/2]\n",
        "        x = self.layer3(x)              # -> [B, 256, H/4, W/4]\n",
        "        x = self.layer4(x)              # -> [B, 384, H/8, W/8]\n",
        "        x = self.cbam(x)                # Apply attention\n",
        "\n",
        "        # Dual pooling strategy\n",
        "        avg_pool = self.global_pool(x)\n",
        "        max_pool = self.global_max_pool(x)\n",
        "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# -------------------- Utility: print params --------------------\n",
        "def count_parameters(model):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total, trainable\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Quick sanity test\n",
        "    model = AdaptSRNetEnhanced(num_classes=1, srm_filters=64)\n",
        "    total, trainable = count_parameters(model)\n",
        "    print(f\"Total params: {total:,}; Trainable: {trainable:,}\")\n",
        "    print(f\"Model size: {total / 1e6:.2f}M parameters\")\n",
        "\n",
        "    # Test forward pass with dummy input\n",
        "    x = torch.randn(2, 1, 256, 256)\n",
        "    with torch.no_grad():\n",
        "        y = model(x)\n",
        "    print(f\"Output shape: {y.shape}\")\n",
        "    print(f\"Model ready for training!\")\n"
      ],
      "metadata": {
        "id": "i-yU64TSXqYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StegoLightningModule(pl.LightningModule):\n",
        "    def __init__(self, model, lr=1e-3):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.lr = lr\n",
        "\n",
        "        # Metrics for binary classification\n",
        "        self.train_acc = Accuracy(task=\"binary\")\n",
        "        self.train_f1 = F1Score(task=\"binary\")\n",
        "        self.val_acc = Accuracy(task=\"binary\")\n",
        "        self.val_f1 = F1Score(task=\"binary\")\n",
        "\n",
        "        # Track best validation accuracy\n",
        "        self.best_val_acc = 0.0\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, _ = batch\n",
        "        y = y.float().unsqueeze(1)\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        # Predictions\n",
        "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "        acc = self.train_acc(preds, y.long())\n",
        "        f1 = self.train_f1(preds, y.long())\n",
        "\n",
        "        # Logging\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"train_f1\", f1, prog_bar=False, on_step=False, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, _ = batch\n",
        "        y = y.float().unsqueeze(1)\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        # Predictions\n",
        "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "        acc = self.val_acc(preds, y.long())\n",
        "        f1 = self.val_f1(preds, y.long())\n",
        "\n",
        "        # Logging\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_f1\", f1, prog_bar=True, on_step=False, on_epoch=True)\n",
        "\n",
        "        return {\"val_loss\": loss, \"val_acc\": acc, \"val_f1\": f1}\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Track best accuracy\n",
        "        val_acc = self.val_acc.compute()\n",
        "        if val_acc > self.best_val_acc:\n",
        "            self.best_val_acc = val_acc\n",
        "            print(f\"\\nNew best validation accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Use AdamW with weight decay for regularization\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            self.parameters(),\n",
        "            lr=self.lr,\n",
        "            weight_decay=1e-4,\n",
        "            betas=(0.9, 0.999)\n",
        "        )\n",
        "\n",
        "        # Cosine annealing with warm restarts for better convergence\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer,\n",
        "            T_0=10,  # Restart every 10 epochs\n",
        "            T_mult=2,  # Double the restart period each time\n",
        "            eta_min=1e-6\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"interval\": \"epoch\",\n",
        "                \"frequency\": 1\n",
        "            }\n",
        "        }\n"
      ],
      "metadata": {
        "id": "ttMwAjAgXuMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set CUDA_LAUNCH_BLOCKING to 1 for synchronous error reporting\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Initialize enhanced model\n",
        "model = AdaptSRNetEnhanced(num_classes=1, srm_filters=64)\n",
        "lightning_model = StegoLightningModule(model, lr=LR)\n",
        "\n",
        "# Print model statistics\n",
        "total, trainable = count_parameters(model)\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Model: AdaptSRNetEnhanced\")\n",
        "print(f\"Total Parameters: {total:,}\")\n",
        "print(f\"Trainable Parameters: {trainable:,}\")\n",
        "print(f\"Model Size: {total / 1e6:.2f}M parameters\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Enhanced callbacks\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    monitor=\"val_acc\",\n",
        "    mode=\"max\",\n",
        "    save_top_k=3,  # Save top 3 models\n",
        "    filename=\"adaptsrnet-{epoch:02d}-{val_acc:.4f}-{val_f1:.4f}\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "early_stop_cb = EarlyStopping(\n",
        "    monitor=\"val_acc\",\n",
        "    mode=\"max\",\n",
        "    patience=10,  # Increased patience\n",
        "    verbose=True,\n",
        "    min_delta=0.001  # Minimum improvement threshold\n",
        ")\n",
        "\n",
        "# Learning rate monitor\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
        "\n",
        "# Enhanced trainer with gradient clipping\n",
        "trainer = Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    precision=\"16-mixed\",\n",
        "    max_epochs=EPOCHS,\n",
        "    callbacks=[checkpoint_cb, early_stop_cb, lr_monitor],\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1.0,  # Gradient clipping to prevent exploding gradients\n",
        "    accumulate_grad_batches=1,  # Can increase for larger effective batch size\n",
        "    deterministic=False,  # Set to True for reproducibility (slower)\n",
        "    enable_progress_bar=True\n",
        ")\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Max epochs: {EPOCHS}\")\n",
        "print(f\"Initial learning rate: {LR}\")\n",
        "print(f\"Training samples: {len(splits['train'])}\")\n",
        "print(f\"Validation samples: {len(splits['val'])}\\n\")\n",
        "\n",
        "trainer.fit(lightning_model, train_loader, val_loader)\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Best validation accuracy: {lightning_model.best_val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "OzCI-8XKX1dt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}